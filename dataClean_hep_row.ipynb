{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Include preprocessing of Cancer dataset:\\n    a) removing the attribute with missing data\\n    b) shuffling the data\\n    c) storing the labels in normalised form\\n    d) Creating (splitting) data into training and test datasets\\n    e) Looking into the statisticaL info of the attributes\\n    f) Visualising the attributes deendency (working on it)'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Include preprocessing of Cancer dataset:\n",
    "    a) removing the attribute with missing data\n",
    "    b) shuffling the data\n",
    "    c) storing the labels in normalised form\n",
    "    d) Creating (splitting) data into training and test datasets\n",
    "    e) Looking into the statisticaL info of the attributes\n",
    "    f) Visualising the attributes deendency (working on it)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hepatitis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 20)\n",
      "155\n"
     ]
    }
   ],
   "source": [
    "size_data = df.shape\n",
    "print(size_data)\n",
    "print(size_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Class', 'AGE', 'SEX', 'STEROID', 'ANTIVIRALS', 'FATIGUE', 'MALAISE', 'ANOREXIA', 'LIVER_BIG', 'LIVER_FIRM', 'SPLEEN_PALPABLE', 'SPIDERS', 'ASCITES', 'VARICES', 'BILIRUBIN', 'ALK_PHOSPHATE', 'SGOT', 'ALBUMIN', 'PROTIME', 'HISTOLOGY']\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "header = []\n",
    "for i in range(size_data[1]):\n",
    "  header.append(df.columns[i])\n",
    "\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 20\n"
     ]
    }
   ],
   "source": [
    "print(len(data), len(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167 [0, 1, 2, 3, 4, 6, 7, 8, 9, 14, 16, 26, 31, 35, 37, 41, 44, 45, 46, 50, 51, 55, 56, 59, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 79, 80, 83, 86, 87, 88, 91, 92, 93, 97, 99, 101, 105, 106, 107, 110, 112, 113, 114, 115, 116, 118, 119, 120, 122, 123, 126, 131, 132, 136, 140, 141, 142, 144, 146, 147, 148, 149, 150, 151, 152]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "data_miss = []\n",
    "for i in range(len(data)):\n",
    "  for j in range(len(data[0])):\n",
    "    if data[i][j] == \"?\":\n",
    "      count += 1\n",
    "      if i in data_miss:\n",
    "        continue\n",
    "      else:\n",
    "        data_miss.append(i)\n",
    "\n",
    "print(count, data_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "dataA = []\n",
    "for i in range(len(data)):\n",
    "    if i not in data_miss:\n",
    "        dataA.append(data[i])\n",
    "        \n",
    "print(len(dataA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA = np.array(dataA)\n",
    "f = open(\"Cleaned_hep_Row.csv\", \"w+\")\n",
    "for i in range(len(header)):\n",
    "    f.write(str(header[i])+\",\")\n",
    "f.write('\\n')    \n",
    "for i in range(len(dataA)):\n",
    "    for j in range(len(dataA[0])):\n",
    "        f.write(str(dataA[i][j])+\",\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 1 2 2 2 2 2 2 2 2 1 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 2 2 2 1 2 2 2 2 1 2 2 2 1 1 2 2 2\n",
      " 1 2 2 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "#initialising arrays for data sorting and shuffling\n",
    "train_data = []\n",
    "train_labels = []\n",
    "test_data = []\n",
    "test_labels = []\n",
    "dataC = dataA\n",
    "\n",
    "#shuffle the dataset\n",
    "np.random.shuffle(dataA)\n",
    "\n",
    "#storing dataset labels\n",
    "#class determines the label Benign or malignant which is in the 11th column (indexing begins from 0) for this dataset\n",
    "labels = dataA[:,0]\n",
    "\n",
    "print(len(labels))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "label_nor = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 1:#die\n",
    "        label_nor.append(0)\n",
    "    elif labels[i] == 2:#live\n",
    "        label_nor.append(1)\n",
    "\n",
    "print(len(label_nor))\n",
    "print(label_nor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since not all of them are in numeric data type, it requires conversion for statistical calculation\n",
    "dataA = dataA.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 60\n"
     ]
    }
   ],
   "source": [
    "#using the first 75% of the shuffled data into training data and labels\n",
    "#Removed columns from original data: the label. Hence, #rem columns = 20-1=19\n",
    "train_data = dataA[:,1:20][:int(len(dataA)*0.75)]\n",
    "train_labels = label_nor[:int(len(label_nor)*0.75)]\n",
    "print(len(train_labels), len(train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20\n",
      "60 19\n",
      "20 19\n",
      "0 [ 48.    1.    1.    2.    1.    1.    2.    2.    1.    2.    1.    1.\n",
      "   1.    4.8 123.  157.    2.7  31.    2. ]\n",
      "1 [ 27.    1.    2.    2.    1.    1.    1.    1.    1.    1.    1.    2.\n",
      "   2.    1.2 133.   98.    4.1  39.    1. ]\n"
     ]
    }
   ],
   "source": [
    "#using the remaining 25% of shuffled data for test data and labels\n",
    "test_data = dataA[:,1:20][int(len(dataA)*0.75):]\n",
    "test_labels = label_nor[int(len(label_nor)*0.75):]\n",
    "\n",
    "print(len(test_labels), len(test_data))\n",
    "print(len(train_labels),len(train_data[0]))\n",
    "print(len(test_labels), len(test_data[0]))\n",
    "print(test_labels[0], test_data[0])\n",
    "print(train_labels[0], train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "np.savetxt(\"train_data_hep_cleanRow.csv\", train_data, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"test_data_hep_cleanRow.csv\", test_data, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"train_labels_hep_cleanRow.csv\", train_labels, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"test_labels_hep_cleanRow.csv\", test_labels, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. AGE\n",
      "\tTraining Set: Minimum: 20.0 Maximum: 72.0 Mean: 39.266666666666666 Median: 38.0\n",
      "\tTesting Set: Minimum: 25.0 Maximum: 65.0 Mean: 44.85 Median: 45.5\n",
      "2. SEX\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.1333333333333333 Median: 1.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.15 Median: 1.0\n",
      "3. STEROID\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.5166666666666666 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.55 Median: 2.0\n",
      "4. ANTIVIRALS\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.7 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.85 Median: 2.0\n",
      "5. FATIGUE\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.3833333333333333 Median: 1.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.25 Median: 1.0\n",
      "6. MALAISE\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.65 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.5 Median: 1.5\n",
      "7. ANOREXIA\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.85 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.85 Median: 2.0\n",
      "8. LIVER_BIG\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.8333333333333333 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.85 Median: 2.0\n",
      "9. LIVER_FIRM\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.5166666666666666 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.55 Median: 2.0\n",
      "10. SPLEEN_PALPABLE\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.8666666666666667 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.65 Median: 2.0\n",
      "11. SPIDERS\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.75 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.5 Median: 1.5\n",
      "12. ASCITES\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.9 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.7 Median: 2.0\n",
      "13. VARICES\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.9166666666666667 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.75 Median: 2.0\n",
      "14. BILIRUBIN\n",
      "\tTraining Set: Minimum: 0.4 Maximum: 4.6 Mean: 1.1483333333333332 Median: 1.0\n",
      "\tTesting Set: Minimum: 0.3 Maximum: 4.8 Mean: 1.44 Median: 1.0\n",
      "15. ALK_PHOSPHATE\n",
      "\tTraining Set: Minimum: 26.0 Maximum: 280.0 Mean: 98.6 Median: 85.0\n",
      "\tTesting Set: Minimum: 50.0 Maximum: 243.0 Mean: 115.85 Median: 100.0\n",
      "16. SGOT\n",
      "\tTraining Set: Minimum: 14.0 Maximum: 420.0 Mean: 82.0 Median: 54.5\n",
      "\tTesting Set: Minimum: 19.0 Maximum: 269.0 Mean: 82.1 Median: 66.0\n",
      "17. ALBUMIN\n",
      "\tTraining Set: Minimum: 2.1 Maximum: 5.0 Mean: 3.8699999999999997 Median: 4.0\n",
      "\tTesting Set: Minimum: 2.4 Maximum: 4.7 Mean: 3.7649999999999997 Median: 3.9\n",
      "18. PROTIME\n",
      "\tTraining Set: Minimum: 0.0 Maximum: 100.0 Mean: 63.483333333333334 Median: 65.0\n",
      "\tTesting Set: Minimum: 29.0 Maximum: 100.0 Mean: 59.6 Median: 54.5\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "# position to get the index from the train_data\n",
    "position = 0\n",
    "# looping through feature names to print out the summary of each attribute for training and testing data\n",
    "for attribute in header:\n",
    "    # leaving out the first and last classes as those are not the attributes\n",
    "    if( count != 0  and count != (len(header)-1)):\n",
    "        print(str(count) + \". \" + attribute + \"\\n\\tTraining Set: Minimum: \" + str(train_data[:,position].min()) + \" Maximum: \" + str(train_data[:,position].max()) + \" Mean: \" + str(train_data[:,position].mean()) + \" Median: \" + str(np.median(train_data[:,position])) + \"\\n\\tTesting Set: Minimum: \" + str(test_data[:,position].min()) + \" Maximum: \" + str(test_data[:,position].max()) + \" Mean: \" + str(test_data[:,position].mean()) + \" Median: \" + str(np.median(test_data[:,position])) )\n",
    "        position +=1\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
