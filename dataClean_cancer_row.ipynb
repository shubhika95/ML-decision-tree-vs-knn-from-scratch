{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Include preprocessing of Cancer dataset:\\n    a) removing the attribute with missing data\\n    b) shuffling the data\\n    c) storing the labels in normalised form\\n    d) Creating (splitting) data into training and test datasets\\n    e) Looking into the statisticaL info of the attributes\\n    f) Visualising the attributes deendency (working on it)'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Include preprocessing of Cancer dataset:\n",
    "    a) removing the instances with missing data\n",
    "    b) shuffling the data\n",
    "    c) storing the labels in normalised form\n",
    "    d) Creating (splitting) data into training and test datasets\n",
    "    e) Looking into the statisticaL info of the attributes'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"breast_cancer_wisconsin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699, 11)\n",
      "699\n"
     ]
    }
   ],
   "source": [
    "size_data = df.shape\n",
    "print(size_data)\n",
    "print(size_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'Clump_Thickness', 'Uniformity_of_Cell_Size', 'Uniformity_of_Cell_Shape', 'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei', 'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses', 'Class']\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "header = []\n",
    "for i in range(size_data[1]):\n",
    "  header.append(df.columns[i])\n",
    "\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699 11\n"
     ]
    }
   ],
   "source": [
    "print(len(data), len(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 [23, 40, 139, 145, 158, 164, 235, 249, 275, 292, 294, 297, 315, 321, 411, 617]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "data_miss = []\n",
    "for i in range(len(data)):\n",
    "  for j in range(len(data[0])):\n",
    "    if data[i][j] == \"?\":\n",
    "      count += 1\n",
    "      if i in data_miss:\n",
    "        continue\n",
    "      else:\n",
    "        data_miss.append(i)\n",
    "\n",
    "print(count, data_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699\n",
      "683\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "dataA = []\n",
    "for i in range(len(data)):\n",
    "    if i not in data_miss:\n",
    "        dataA.append(data[i])\n",
    "        \n",
    "print(len(dataA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA = np.array(dataA)\n",
    "f = open(\"Cleaned_Cancer_Row.csv\", \"w+\")\n",
    "for i in range(len(header)):\n",
    "    f.write(str(header[i])+\",\")\n",
    "f.write('\\n')\n",
    "for i in range(len(dataA)):\n",
    "    for j in range(len(dataA[0])):\n",
    "        f.write(str(dataA[i][j])+\",\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683\n",
      "[2 2 2 2 2 4 2 2 4 2 2 4 4 2 2 4 2 4 2 2 4 2 2 2 4 4 2 4 2 2 4 4 4 2 2 2 4\n",
      " 2 2 2 4 2 4 4 4 4 4 2 2 2 2 2 4 4 4 4 4 4 4 4 4 2 2 4 4 2 4 2 4 2 2 4 4 2\n",
      " 4 2 2 4 2 2 4 2 4 2 2 2 2 2 2 2 2 2 4 4 2 2 2 4 2 4 2 2 2 4 4 4 2 4 2 2 2\n",
      " 2 4 4 4 2 2 4 2 4 2 2 2 2 2 2 2 2 2 4 2 2 2 4 2 4 4 4 2 4 4 2 2 2 4 4 2 2\n",
      " 4 2 2 2 2 2 2 4 2 4 4 4 2 2 2 2 2 4 4 2 2 2 4 2 4 2 2 2 4 2 4 2 4 2 4 4 4\n",
      " 4 2 2 4 4 4 2 2 4 2 2 2 2 2 2 2 4 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 4 4 4 2\n",
      " 2 2 2 2 2 2 2 2 4 4 4 4 2 2 2 2 2 2 4 4 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 4\n",
      " 2 4 4 2 4 2 2 4 2 4 4 2 4 2 2 4 2 4 4 2 2 4 4 4 2 2 2 2 2 4 4 2 2 4 2 2 2\n",
      " 2 4 2 2 2 2 4 4 2 4 2 4 2 2 2 2 4 4 2 4 2 2 2 2 2 4 2 2 2 4 4 4 4 2 4 4 2\n",
      " 4 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 4 4 4 2 2 2 4 2 2 2 4 4 2 2 2 2\n",
      " 2 2 4 2 2 2 2 4 2 4 2 2 2 2 2 2 2 4 4 2 2 2 2 4 2 2 2 4 4 2 2 2 4 4 2 2 4\n",
      " 4 2 2 4 2 2 4 4 2 4 4 4 4 2 2 2 2 4 2 4 2 4 2 4 2 2 2 2 2 4 2 2 2 2 4 2 4\n",
      " 4 2 4 2 2 4 4 4 2 2 4 2 2 2 2 4 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 4 4 2 2\n",
      " 2 2 4 4 2 4 2 2 2 2 4 2 2 4 2 2 4 2 2 4 2 2 4 2 2 4 2 4 2 4 4 2 2 4 2 2 2\n",
      " 2 4 2 2 4 2 2 2 2 4 4 2 4 2 2 4 2 2 4 2 2 2 2 2 4 2 2 4 2 2 2 2 2 4 2 4 4\n",
      " 2 2 2 2 2 2 4 4 4 4 4 4 2 2 2 2 2 4 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 4 2 4 2\n",
      " 2 4 2 2 2 2 2 2 4 4 2 4 2 4 2 2 2 2 2 4 2 2 2 2 2 2 2 4 4 4 2 2 2 2 4 2 2\n",
      " 2 4 2 4 2 2 2 4 2 4 2 2 4 2 2 2 2 2 2 2 2 4 4 2 4 4 2 2 4 2 4 4 4 4 2 2 2\n",
      " 2 4 4 4 2 2 4 2 2 2 2 2 2 4 2 2 4]\n"
     ]
    }
   ],
   "source": [
    "#initialising arrays for data sorting and shuffling\n",
    "train_data = []\n",
    "train_labels = []\n",
    "test_data = []\n",
    "test_labels = []\n",
    "dataC = dataA\n",
    "\n",
    "#shuffle the dataset\n",
    "np.random.shuffle(dataA)\n",
    "\n",
    "#storing dataset labels\n",
    "#class determines the label Benign or malignant which is in the 11th column (indexing begins from 0) for this dataset\n",
    "labels = dataA[:,10]\n",
    "\n",
    "print(len(labels))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "label_nor = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 2:#benign\n",
    "        label_nor.append(0)\n",
    "    elif labels[i] == 4:#malignant\n",
    "        label_nor.append(1)\n",
    "\n",
    "print(len(label_nor))\n",
    "print(label_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since not all of them are in numeric data type, it requires conversion for statistical calculation\n",
    "dataA = dataA.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 512\n"
     ]
    }
   ],
   "source": [
    "#using the first 75% of the shuffled data into training data and labels\n",
    "#Removed columns from original data: ID, the one with missing data, and the label. Hence, #rem columns = 11-2=9\n",
    "train_data = dataA[:,1:10][:int(len(dataA)*0.75)]\n",
    "train_labels = label_nor[:int(len(label_nor)*0.75)]\n",
    "print(len(train_labels), len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 171\n",
      "512 9\n",
      "171 9\n",
      "0 [2. 1. 1. 1. 2. 1. 1. 1. 1.]\n",
      "0 [5. 1. 2. 1. 2. 1. 3. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#using the remaining 25% of shuffled data for test data and labels\n",
    "test_data = dataA[:,1:10][int(len(dataA)*0.75):]\n",
    "test_labels = label_nor[int(len(label_nor)*0.75):]\n",
    "print(len(test_labels), len(test_data))\n",
    "print(len(train_labels),len(train_data[0]))\n",
    "print(len(test_labels), len(test_data[0]))\n",
    "print(test_labels[0], test_data[0])\n",
    "print(train_labels[0], train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "np.savetxt(\"train_data_Cancer_cleanRow.csv\", train_data, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"test_data_Cancer_cleanRow.csv\", test_data, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"train_labels_Cancer_cleanRow.csv\", train_labels, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"test_labels_Cancer_cleanRow.csv\", test_labels, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Clump_Thickness\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 10.0 Mean: 4.55078125 Median: 4.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 10.0 Mean: 4.116959064327485 Median: 4.0\n",
      "2. Uniformity_of_Cell_Size\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 10.0 Mean: 3.228515625 Median: 1.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 10.0 Mean: 2.91812865497076 Median: 1.0\n",
      "3. Uniformity_of_Cell_Shape\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 10.0 Mean: 3.31640625 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 10.0 Mean: 2.912280701754386 Median: 1.0\n",
      "4. Marginal_Adhesion\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 10.0 Mean: 2.912109375 Median: 1.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 10.0 Mean: 2.584795321637427 Median: 1.0\n",
      "5. Single_Epithelial_Cell_Size\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 10.0 Mean: 3.291015625 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 10.0 Mean: 3.064327485380117 Median: 2.0\n",
      "6. Bare_Nuclei\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 10.0 Mean: 3.609375 Median: 1.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 10.0 Mean: 3.3508771929824563 Median: 1.0\n",
      "7. Bland_Chromatin\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 10.0 Mean: 3.486328125 Median: 3.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 10.0 Mean: 3.3216374269005846 Median: 3.0\n",
      "8. Normal_Nucleoli\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 10.0 Mean: 2.95703125 Median: 1.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 10.0 Mean: 2.608187134502924 Median: 1.0\n",
      "9. Mitoses\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 10.0 Mean: 1.671875 Median: 1.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 10.0 Mean: 1.3976608187134503 Median: 1.0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "# position to get the index from the train_data\n",
    "position = 0\n",
    "# looping through feature names to print out the summary of each attribute for training and testing data\n",
    "for attribute in header:\n",
    "    # leaving out the first and last classes as those are not the attributes\n",
    "    if( count != 0  and count != (len(header)-1)):\n",
    "        print(str(count) + \". \" + attribute + \"\\n\\tTraining Set: Minimum: \" + str(train_data[:,position].min()) + \" Maximum: \" + str(train_data[:,position].max()) + \" Mean: \" + str(train_data[:,position].mean()) + \" Median: \" + str(np.median(train_data[:,position])) + \"\\n\\tTesting Set: Minimum: \" + str(test_data[:,position].min()) + \" Maximum: \" + str(test_data[:,position].max()) + \" Mean: \" + str(test_data[:,position].mean()) + \" Median: \" + str(np.median(test_data[:,position])) )\n",
    "        position +=1\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
