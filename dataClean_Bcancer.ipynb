{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Include preprocessing of Cancer dataset:\\n    a) Substituting the missing data with mean of that attribute\\n    b) shuffling the data\\n    c) storing the labels in normalised form\\n    d) Creating (splitting) data into training and test datasets\\n    e) Looking into the statisticaL info of the attributes\\n    f) Visualising the attributes deendency (working on it)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Include preprocessing of Cancer dataset:\n",
    "    a) Substituting the missing data with mean of that attribute\n",
    "    b) shuffling the data\n",
    "    c) storing the labels in normalised form\n",
    "    d) Creating (splitting) data into training and test datasets\n",
    "    e) Looking into the statisticaL info of the attributes\n",
    "    f) Visualising the attributes deendency (working on it)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"breast_cancer_wisconsin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699, 11)\n",
      "699\n"
     ]
    }
   ],
   "source": [
    "size_data = df.shape\n",
    "print(size_data)\n",
    "print(size_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'Clump_Thickness', 'Uniformity_of_Cell_Size', 'Uniformity_of_Cell_Shape', 'Marginal_Adhesion', 'Single_Epithelial_Cell_Size', 'Bare_Nuclei', 'Bland_Chromatin', 'Normal_Nucleoli', 'Mitoses', 'Class']\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "header = []\n",
    "for i in range(size_data[1]):\n",
    "  header.append(df.columns[i])\n",
    "\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699 11\n"
     ]
    }
   ],
   "source": [
    "print(len(data), len(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 [6]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "data_miss = []\n",
    "for i in(range(len(data[0]))):\n",
    "  for j in range(len(data)):\n",
    "    if data[j][i] == \"?\":\n",
    "      count += 1\n",
    "      if i in data_miss:\n",
    "        continue\n",
    "      else:\n",
    "        data_miss.append(i)\n",
    "\n",
    "print(count, data_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5446559297218156\n",
      "[23, 40, 139, 145, 158, 164, 235, 249, 275, 292, 294, 297, 315, 321, 411, 617] 16\n",
      "23\n",
      "3.5446559297218156\n",
      "40\n",
      "3.5446559297218156\n",
      "139\n",
      "3.5446559297218156\n",
      "145\n",
      "3.5446559297218156\n",
      "158\n",
      "3.5446559297218156\n",
      "164\n",
      "3.5446559297218156\n",
      "235\n",
      "3.5446559297218156\n",
      "249\n",
      "3.5446559297218156\n",
      "275\n",
      "3.5446559297218156\n",
      "292\n",
      "3.5446559297218156\n",
      "294\n",
      "3.5446559297218156\n",
      "297\n",
      "3.5446559297218156\n",
      "315\n",
      "3.5446559297218156\n",
      "321\n",
      "3.5446559297218156\n",
      "411\n",
      "3.5446559297218156\n",
      "617\n",
      "3.5446559297218156\n"
     ]
    }
   ],
   "source": [
    "for i in data_miss:\n",
    "  c = 0\n",
    "  ind = []\n",
    "  sum = 0\n",
    "  for j in range(len(data)):\n",
    "    if data[j][i] != \"?\":\n",
    "      data[j][i] = float(data[j][i])\n",
    "      sum = sum+ int(data[j][i])\n",
    "    else:\n",
    "      c += 1\n",
    "      ind.append(j)\n",
    "  sub_mean = sum/(len(data)-c)\n",
    "  print(sub_mean)\n",
    "  print(ind, c)\n",
    "  for j in ind:\n",
    "    print(j)\n",
    "    data[j][i] = sub_mean\n",
    "    print(data[j][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"SubData_cancer.csv\", \"w+\")\n",
    "for i in range(len(header)):\n",
    "    f.write(str(header[i])+\",\")\n",
    "f.write('\\n')\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data[0])):\n",
    "        f.write(str(data[i][j])+\",\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699 11\n"
     ]
    }
   ],
   "source": [
    "#initialising arrays for data sorting and shuffling\n",
    "train_data = []\n",
    "train_labels = []\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "#shuffle the dataset\n",
    "np.random.shuffle(data)\n",
    "print(len(data), len(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing dataset labels\n",
    "#class determines the label Benign or malignant which is in the 11th column (indexing begins from 0) for this dataset\n",
    "labels = data[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699\n",
      "[0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "label_nor = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 2:#benign\n",
    "        label_nor.append(0)\n",
    "    elif labels[i] == 4:#malignant\n",
    "        label_nor.append(1)\n",
    "\n",
    "print(len(label_nor))\n",
    "print(label_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524 524\n"
     ]
    }
   ],
   "source": [
    "#using the first 75% of the shuffled data into training data and labels\n",
    "train_data = data[:,0:10][:int(len(data)*0.75)]\n",
    "train_labels = data[:,10:][:int(len(data)*0.75)]\n",
    "print(len(train_labels), len(train_data))\n",
    "#print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 175\n"
     ]
    }
   ],
   "source": [
    "#using the remaining 25% of shuffled data for test data and labels\n",
    "test_data = data[:,0:10][int(len(data)*0.75):]\n",
    "test_labels = data[:,10:][int(len(data)*0.75):]\n",
    "print(len(test_labels), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "np.savetxt(\"train_data_cleanedCancer.csv\", train_data, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"test_data_cleanedCancer.csv\", test_data, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"train_labels_cleanedCancer.csv\", train_labels, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"test_labels_cleanedCancer.csv\", test_labels, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Clump_Thickness\n",
      "\tTraining Set: Minimum: 61634 Maximum: 13454352 Mean: 1079931.996183206 Median: 1172684.0\n",
      "\tTesting Set: Minimum: 95719 Maximum: 1355260 Mean: 1047067.4228571429 Median: 1168736.0\n",
      "2. Uniformity_of_Cell_Size\n",
      "\tTraining Set: Minimum: 1 Maximum: 10 Mean: 4.488549618320611 Median: 4.0\n",
      "\tTesting Set: Minimum: 1 Maximum: 10 Mean: 4.2057142857142855 Median: 4.0\n",
      "3. Uniformity_of_Cell_Shape\n",
      "\tTraining Set: Minimum: 1 Maximum: 10 Mean: 3.1393129770992365 Median: 1.0\n",
      "\tTesting Set: Minimum: 1 Maximum: 10 Mean: 3.12 Median: 1.0\n",
      "4. Marginal_Adhesion\n",
      "\tTraining Set: Minimum: 1 Maximum: 10 Mean: 3.217557251908397 Median: 1.0\n",
      "\tTesting Set: Minimum: 1 Maximum: 10 Mean: 3.177142857142857 Median: 1.0\n",
      "5. Single_Epithelial_Cell_Size\n",
      "\tTraining Set: Minimum: 1 Maximum: 10 Mean: 2.812977099236641 Median: 1.0\n",
      "\tTesting Set: Minimum: 1 Maximum: 10 Mean: 2.7885714285714287 Median: 1.0\n",
      "7. Bland_Chromatin\n",
      "\tTraining Set: Minimum: 1 Maximum: 10 Mean: 3.25381679389313 Median: 2.0\n",
      "\tTesting Set: Minimum: 1 Maximum: 10 Mean: 3.1028571428571428 Median: 2.0\n",
      "8. Normal_Nucleoli\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 10.0 Mean: 3.6028662278005656 Median: 1.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 10.0 Mean: 3.3703576657603014 Median: 1.0\n",
      "9. Mitoses\n",
      "\tTraining Set: Minimum: 1 Maximum: 10 Mean: 3.437022900763359 Median: 3.0\n",
      "\tTesting Set: Minimum: 1 Maximum: 10 Mean: 3.44 Median: 3.0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "# position to get the index from the train_data\n",
    "position = 0\n",
    "# looping through feature names to print out the summary of each attribute for training and testing data\n",
    "for attribute in header:\n",
    "    # leaving out the first and last classes as those are not the attributes\n",
    "    if( count != 0 and count not in data_miss and count != (len(header)-1)):\n",
    "        print(str(count) + \". \" + attribute + \"\\n\\tTraining Set: Minimum: \" + str(train_data[:,position].min()) + \" Maximum: \" + str(train_data[:,position].max()) + \" Mean: \" + str(train_data[:,position].mean()) + \" Median: \" + str(np.median(train_data[:,position])) + \"\\n\\tTesting Set: Minimum: \" + str(test_data[:,position].min()) + \" Maximum: \" + str(test_data[:,position].max()) + \" Mean: \" + str(test_data[:,position].mean()) + \" Median: \" + str(np.median(test_data[:,position])) )\n",
    "        position +=1\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
