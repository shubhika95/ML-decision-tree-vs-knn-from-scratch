{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Include preprocessing of Hepatitis dataset:\n",
    "    a) substituting the missing data with mean or mode for cont or categorical attribute repectively\n",
    "    b) shuffling the data\n",
    "    c) storing the labels in normalised form\n",
    "    d) Creating (splitting) data into training and test datasets\n",
    "    e) Looking into the statisticaL info of the attributes'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"hepatitis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 20)\n",
      "155\n"
     ]
    }
   ],
   "source": [
    "size_data = df.shape\n",
    "print(size_data)\n",
    "print(size_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Class', 'AGE', 'SEX', 'STEROID', 'ANTIVIRALS', 'FATIGUE', 'MALAISE', 'ANOREXIA', 'LIVER_BIG', 'LIVER_FIRM', 'SPLEEN_PALPABLE', 'SPIDERS', 'ASCITES', 'VARICES', 'BILIRUBIN', 'ALK_PHOSPHATE', 'SGOT', 'ALBUMIN', 'PROTIME', 'HISTOLOGY']\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "header = []\n",
    "for i in range(size_data[1]):\n",
    "  header.append(df.columns[i])\n",
    "\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 20\n"
     ]
    }
   ],
   "source": [
    "print(len(data), len(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167 [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "data_miss = []\n",
    "for i in(range(len(data[0]))):\n",
    "  for j in range(len(data)):\n",
    "    if data[j][i] == \"?\":\n",
    "      count += 1\n",
    "      if i in data_miss:\n",
    "        continue\n",
    "      else:\n",
    "        data_miss.append(i)\n",
    "\n",
    "print(count, data_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "provide A for categorical values and B for continous values\n",
      "Attribute to be handled: STEROID\n",
      "a\n",
      "Attribute to be handled: FATIGUE\n",
      "a\n",
      "Attribute to be handled: MALAISE\n",
      "a\n",
      "Attribute to be handled: ANOREXIA\n",
      "a\n",
      "Attribute to be handled: LIVER_BIG\n",
      "a\n",
      "Attribute to be handled: LIVER_FIRM\n",
      "a\n",
      "Attribute to be handled: SPLEEN_PALPABLE\n",
      "a\n",
      "Attribute to be handled: SPIDERS\n",
      "a\n",
      "Attribute to be handled: ASCITES\n",
      "a\n",
      "Attribute to be handled: VARICES\n",
      "a\n",
      "Attribute to be handled: BILIRUBIN\n",
      "b\n",
      "Attribute to be handled: ALK_PHOSPHATE\n",
      "b\n",
      "Attribute to be handled: SGOT\n",
      "b\n",
      "Attribute to be handled: ALBUMIN\n",
      "b\n",
      "Attribute to be handled: PROTIME\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"provide A for categorical values and B for continous values\")\n",
    "\n",
    "for i in data_miss:\n",
    "    print(\"Attribute to be handled: \"+str(header[i]))\n",
    "    interaction = input()\n",
    "    if interaction == \"A\" or interaction == \"a\":\n",
    "        #calculate mode\n",
    "        mode = 0\n",
    "        ind = []\n",
    "        arr = []\n",
    "        for j in range(len(data)):\n",
    "            if data[j][i] != \"?\":\n",
    "                data[j][i] = float(data[j][i])\n",
    "                arr.append(data[j][i])\n",
    "            else:\n",
    "                ind.append(j)\n",
    "        incomp_data = Counter(arr)\n",
    "        get_mode = dict(incomp_data)\n",
    "        \n",
    "        mode = [k for k, v in get_mode.items() if v == max(list(incomp_data.values()))]\n",
    "        \n",
    "        if len(mode) == len(arr):\n",
    "            print(\"no mode found\")\n",
    "        else:\n",
    "            for j in ind:\n",
    "                data[j][i] = mode[0]\n",
    "        \n",
    "    elif interaction == \"B\" or interaction == \"b\":\n",
    "        #calculate mean\n",
    "        sub_mean = 0\n",
    "        c = 0\n",
    "        ind = []\n",
    "        sum = 0\n",
    "        for j in range(len(data)):\n",
    "            if data[j][i] != \"?\":\n",
    "                data[j][i] = float(data[j][i])\n",
    "                sum = sum+data[j][i]\n",
    "            else:\n",
    "                c = c+1\n",
    "                ind.append(j)\n",
    "        sub_mean = sum/(len(data)-c)\n",
    "        \n",
    "        for j in ind:\n",
    "            data[j][i] = sub_mean\n",
    "    else:\n",
    "        print(\"Invalid input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n"
     ]
    }
   ],
   "source": [
    "#to check if the substitution worked properly\n",
    "\n",
    "count = 0\n",
    "data_miss = []\n",
    "for i in(range(len(data[0]))):\n",
    "  for j in range(len(data)):\n",
    "    if data[j][i] == \"?\":\n",
    "      count += 1\n",
    "      if i in data_miss:\n",
    "        continue\n",
    "      else:\n",
    "        data_miss.append(i)\n",
    "\n",
    "print(count, data_miss)\n",
    "\n",
    "f = open(\"SubData_hepatitis.csv\", \"w+\")\n",
    "for i in range(len(header)):\n",
    "    f.write(str(header[i])+\",\")\n",
    "f.write('\\n')\n",
    "for i in range(len(data)):\n",
    "    for j in range(len(data[0])):\n",
    "        f.write(str(data[i][j])+\",\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 20\n"
     ]
    }
   ],
   "source": [
    "#initialising arrays for data sorting and shuffling\n",
    "train_data = []\n",
    "train_labels = []\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "#shuffle the dataset\n",
    "np.random.shuffle(data)\n",
    "print(len(data), len(data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 [2 2 1 1 2 2 1 2 2 2 2 2 2 2 2 1 2 1 1 1 2 2 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 1 2 1 2 2 2 2 2 2 2 2 1 1 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2 1 2 2 2 1 2 1 2 1 2 2 1 2 2\n",
      " 2 1 1 2 2 2 1]\n"
     ]
    }
   ],
   "source": [
    "#storing dataset labels\n",
    "#class determines the label Benign or malignant which is in the 11th column (indexing begins from 0) for this dataset\n",
    "labels = data[:,0]\n",
    "print(len(labels), labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      "[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "label_nor = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 1:#die\n",
    "        label_nor.append(0)\n",
    "    elif labels[i] == 2:#live\n",
    "        label_nor.append(1)\n",
    "\n",
    "print(len(label_nor))\n",
    "print(label_nor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 116\n"
     ]
    }
   ],
   "source": [
    "#using the first 75% of the shuffled data into training data and labels\n",
    "#Removed columns from original data: labels. Hence, #rem columns = 20-1=19\n",
    "train_data = data[:,1:20][:int(len(data)*0.75)]\n",
    "train_labels = label_nor[:int(len(label_nor)*0.75)]\n",
    "print(len(train_labels), len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the remaining 25% of shuffled data for test data and labels\n",
    "test_data = data[:,1:20][int(len(data)*0.75):]\n",
    "test_labels = label_nor[int(len(label_nor)*0.75):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 39\n",
      "116 19\n",
      "39 19\n",
      "1 [28 2 2.0 2 1.0 1.0 2.0 2.0 1.0 2.0 2.0 2.0 2.0 1.8 191.0 420.0 3.3 46.0 1]\n",
      "1 [34 2 1.0 1 2.0 2.0 2.0 2.0 1.0 2.0 2.0 2.0 2.0 0.6 30.0 24.0 4.0 76.0 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(test_labels), len(test_data))\n",
    "print(len(train_labels),len(train_data[0]))\n",
    "print(len(test_labels), len(test_data[0]))\n",
    "print(test_labels[0], test_data[0])\n",
    "print(train_labels[0], train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "np.savetxt(\"train_data_cleanedHepatitis.csv\", train_data, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"test_data_cleanedHepatitis.csv\", test_data, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"train_labels_cleanedHepatitis.csv\", train_labels, delimiter=\",\", fmt='%s')\n",
    "np.savetxt(\"test_labels_cleanedHepatitis.csv\", test_labels, delimiter=\",\", fmt='%s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. AGE\n",
      "\tTraining Set: Minimum: 20 Maximum: 78 Mean: 40.741379310344826 Median: 38.0\n",
      "\tTesting Set: Minimum: 7 Maximum: 72 Mean: 42.56410256410256 Median: 42.0\n",
      "2. SEX\n",
      "\tTraining Set: Minimum: 1 Maximum: 2 Mean: 1.1120689655172413 Median: 1.0\n",
      "\tTesting Set: Minimum: 1 Maximum: 2 Mean: 1.0769230769230769 Median: 1.0\n",
      "3. STEROID\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.5344827586206897 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.435897435897436 Median: 1.0\n",
      "4. ANTIVIRALS\n",
      "\tTraining Set: Minimum: 1 Maximum: 2 Mean: 1.8448275862068966 Median: 2.0\n",
      "\tTesting Set: Minimum: 1 Maximum: 2 Mean: 1.8461538461538463 Median: 2.0\n",
      "5. FATIGUE\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.3706896551724137 Median: 1.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.2820512820512822 Median: 1.0\n",
      "6. MALAISE\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.6206896551724137 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.564102564102564 Median: 2.0\n",
      "7. ANOREXIA\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.8017241379310345 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.7692307692307692 Median: 2.0\n",
      "8. LIVER_BIG\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.853448275862069 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.794871794871795 Median: 2.0\n",
      "9. LIVER_FIRM\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.6120689655172413 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.6153846153846154 Median: 2.0\n",
      "10. SPLEEN_PALPABLE\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.8189655172413792 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.7692307692307692 Median: 2.0\n",
      "11. SPIDERS\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.6637931034482758 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.6923076923076923 Median: 2.0\n",
      "12. ASCITES\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.853448275862069 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.9230769230769231 Median: 2.0\n",
      "13. VARICES\n",
      "\tTraining Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.8620689655172413 Median: 2.0\n",
      "\tTesting Set: Minimum: 1.0 Maximum: 2.0 Mean: 1.9487179487179487 Median: 2.0\n",
      "14. BILIRUBIN\n",
      "\tTraining Set: Minimum: 0.4 Maximum: 7.6 Mean: 1.4000867854663266 Median: 1.0\n",
      "\tTesting Set: Minimum: 0.3 Maximum: 8.0 Mean: 1.5091034245396664 Median: 1.0\n",
      "15. ALK_PHOSPHATE\n",
      "\tTraining Set: Minimum: 26.0 Maximum: 295.0 Mean: 105.72550629447184 Median: 102.0\n",
      "\tTesting Set: Minimum: 34.0 Maximum: 280.0 Mean: 104.13532763532761 Median: 100.0\n",
      "16. SGOT\n",
      "\tTraining Set: Minimum: 14.0 Maximum: 648.0 Mean: 85.71369034026034 Median: 58.0\n",
      "\tTesting Set: Minimum: 14.0 Maximum: 528.0 Mean: 86.43046357615894 Median: 60.0\n",
      "17. ALBUMIN\n",
      "\tTraining Set: Minimum: 2.1 Maximum: 6.4 Mean: 3.8423033986603783 Median: 3.9\n",
      "\tTesting Set: Minimum: 2.2 Maximum: 4.9 Mean: 3.7427965320051637 Median: 3.8172661870503592\n",
      "18. PROTIME\n",
      "\tTraining Set: Minimum: 0.0 Maximum: 100.0 Mean: 62.45356583072104 Median: 61.85227272727273\n",
      "\tTesting Set: Minimum: 29.0 Maximum: 100.0 Mean: 60.063811188811165 Median: 61.85227272727273\n",
      "19. HISTOLOGY\n",
      "\tTraining Set: Minimum: 1 Maximum: 2 Mean: 1.4396551724137931 Median: 1.0\n",
      "\tTesting Set: Minimum: 1 Maximum: 2 Mean: 1.4871794871794872 Median: 1.0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "# position to get the index from the train_data\n",
    "position = 0\n",
    "# looping through feature names to print out the summary of each attribute for training and testing data\n",
    "for attribute in header:\n",
    "    # leaving out the first attribute which is the label\n",
    "    if( count != 0):\n",
    "        print(str(count) + \". \" + attribute + \"\\n\\tTraining Set: Minimum: \" + str(train_data[:,position].min()) + \" Maximum: \" + str(train_data[:,position].max()) + \" Mean: \" + str(train_data[:,position].mean()) + \" Median: \" + str(np.median(train_data[:,position])) + \"\\n\\tTesting Set: Minimum: \" + str(test_data[:,position].min()) + \" Maximum: \" + str(test_data[:,position].max()) + \" Mean: \" + str(test_data[:,position].mean()) + \" Median: \" + str(np.median(test_data[:,position])) )\n",
    "        position +=1\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
